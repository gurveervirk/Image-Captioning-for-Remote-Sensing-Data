{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"arampacha/rsicd\")","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:57.578614Z","iopub.execute_input":"2024-03-09T06:55:57.579429Z","iopub.status.idle":"2024-03-09T06:55:58.035455Z","shell.execute_reply.started":"2024-03-09T06:55:57.579398Z","shell.execute_reply":"2024-03-09T06:55:58.034334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.037432Z","iopub.execute_input":"2024-03-09T06:55:58.038285Z","iopub.status.idle":"2024-03-09T06:55:58.042112Z","shell.execute_reply.started":"2024-03-09T06:55:58.038257Z","shell.execute_reply":"2024-03-09T06:55:58.041078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom accelerate import Accelerator, notebook_launcher\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.043379Z","iopub.execute_input":"2024-03-09T06:55:58.043669Z","iopub.status.idle":"2024-03-09T06:55:58.054298Z","shell.execute_reply.started":"2024-03-09T06:55:58.043645Z","shell.execute_reply":"2024-03-09T06:55:58.053281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataset, processor):\n        self.dataset = dataset\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        # remove batch dimension\n        encodings = []\n        for caption in item[\"captions\"]:\n            encoding = self.processor(images=item[\"image\"], text=caption, padding=\"max_length\", return_tensors=\"pt\")\n            encoding = {k:v.squeeze() for k,v in encoding.items()}\n            encodings.append(encoding)\n        return encodings","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.056825Z","iopub.execute_input":"2024-03-09T06:55:58.057123Z","iopub.status.idle":"2024-03-09T06:55:58.066019Z","shell.execute_reply.started":"2024-03-09T06:55:58.057100Z","shell.execute_reply":"2024-03-09T06:55:58.065046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.067243Z","iopub.execute_input":"2024-03-09T06:55:58.067775Z","iopub.status.idle":"2024-03-09T06:55:58.079884Z","shell.execute_reply.started":"2024-03-09T06:55:58.067739Z","shell.execute_reply":"2024-03-09T06:55:58.078977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the tokenizer, processor, and model\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.080976Z","iopub.execute_input":"2024-03-09T06:55:58.081242Z","iopub.status.idle":"2024-03-09T06:55:58.291822Z","shell.execute_reply.started":"2024-03-09T06:55:58.081212Z","shell.execute_reply":"2024-03-09T06:55:58.290899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(dataset[\"train\"], processor)\nval_dataset = CustomDataset(dataset[\"valid\"], processor)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.292934Z","iopub.execute_input":"2024-03-09T06:55:58.293200Z","iopub.status.idle":"2024-03-09T06:55:58.311472Z","shell.execute_reply.started":"2024-03-09T06:55:58.293177Z","shell.execute_reply":"2024-03-09T06:55:58.310554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_loop(mixed_precision=\"fp16\", num_epochs=3, learning_rate=5e-5):\n    # Initialize accelerator\n    accelerator = Accelerator(mixed_precision=mixed_precision)\n    \n    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n    \n    # Use DataLoader for efficient batching\n    train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=5, shuffle=False)\n    \n    # Set up the optimizer and learning rate scheduler\n    optimizer = AdamW(model.parameters(), lr=learning_rate)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    \n    model, optimizer, train_loader, val_loader = accelerator.prepare(model, optimizer, train_loader, val_loader)\n    \n    model.train()\n    for epoch in range(num_epochs):\n        epoch_losses = []  # To store losses for each batch in the epoch\n\n        for idx, encodings in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", unit=\"batch\")):\n            for encoding in encodings:\n                input_ids = encoding.pop(\"input_ids\")\n                pixel_values = encoding.pop(\"pixel_values\")\n\n                outputs = model(input_ids=input_ids,\n                                pixel_values=pixel_values,\n                                labels=input_ids)\n\n                loss = outputs.loss\n                epoch_losses.append(loss.item())  # Store the loss for this batch\n\n                accelerator.backward(loss)\n\n                optimizer.step()\n                optimizer.zero_grad()\n\n        # Calculate and print the average loss for the epoch\n        average_loss = sum(epoch_losses) / len(epoch_losses)\n        accelerator.print(f\"Average Training Loss for Epoch {epoch + 1}: {average_loss}\")\n\n        # Validation phase\n        model.eval()\n        val_losses = []\n\n        with torch.no_grad():\n            for val_encodings in tqdm(val_loader, desc=\"Validation\", unit=\"batch\"):\n                for val_encoding in val_encodings:\n                    val_input_ids = val_encoding.pop(\"input_ids\")\n                    val_pixel_values = val_encoding.pop(\"pixel_values\")\n\n                    val_outputs = model(input_ids=val_input_ids,\n                                        pixel_values=val_pixel_values,\n                                        labels=val_input_ids)\n\n                    val_loss = val_outputs.loss\n                    val_losses.append(val_loss.item())\n\n        average_val_loss = sum(val_losses) / len(val_losses)\n        accelerator.print(f\"Average Validation Loss for Epoch {epoch + 1}: {average_val_loss}\")\n\n        # Update learning rate based on validation loss\n        scheduler.step(average_val_loss)\n\n        model.train()\n\n    # Save the fine-tuned model\n        unwrapped_model = accelerator.unwrap_model(model)\n        unwrapped_model.save_pretrained(\n            f\"new_model_epoch_{epoch + 1}\",\n            is_main_process=accelerator.is_main_process,\n            save_function=accelerator.save,\n        )","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.323104Z","iopub.execute_input":"2024-03-09T06:55:58.323822Z","iopub.status.idle":"2024-03-09T06:55:58.339791Z","shell.execute_reply.started":"2024-03-09T06:55:58.323790Z","shell.execute_reply":"2024-03-09T06:55:58.338864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = (\"fp16\", 5, 5e-7)\nnotebook_launcher(training_loop, args, num_processes=2)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T06:55:58.342567Z","iopub.execute_input":"2024-03-09T06:55:58.343092Z","iopub.status.idle":"2024-03-09T06:57:06.615727Z","shell.execute_reply.started":"2024-03-09T06:55:58.343058Z","shell.execute_reply":"2024-03-09T06:57:06.614306Z"},"trusted":true},"execution_count":null,"outputs":[]}]}